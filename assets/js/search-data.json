{
  
    
        "post0": {
            "title": "Step 1 - Collect data",
            "content": "Model form&#229;l . Genkende hunderacer med et givet billede. Derudover skal modellen også kunne genkende hvorvidt et givent billede af en hund er en blandingsrace eller ej. . !pip install -Uqq fastbook import fastbook fastbook.setup_book() . |████████████████████████████████| 727kB 6.8MB/s |████████████████████████████████| 1.2MB 27.6MB/s |████████████████████████████████| 51kB 8.3MB/s |████████████████████████████████| 204kB 48.1MB/s |████████████████████████████████| 61kB 9.8MB/s |████████████████████████████████| 61kB 10.1MB/s Mounted at /content/gdrive . from fastbook import * from fastai.vision.widgets import * from fastai.callback.fp16 import * . Da vi skulle kunne genkende forskellige hunderacer, samt hvorvidt en given hund er et “gadekryds”, var vores første opgave at finde et passende dataset. Tíl at genkende hunderacerne brugte vi Stanford Dogs datasættet fra Kaggle, der består af over 20.000 billeder fordelt på 120 hunderacer. Vi overvejede også at bruge metoder til at skrabe enten Bing eller Google for hundebilleder, men da den fremgangsmåde ville kræve meget mere finkæmning af data, valgte vi at gå med det allerede eksisterende datasæt fra Kaggle. . !unzip &#39;/content/gdrive/MyDrive/dogs.zip&#39; -d &#39;/content/&#39; . train_path = Path(&#39;/content/dogs&#39;) . I forhold til gadekryds var vi dog nødsaget til at lave vores datasæt ud fra google-images søgning, men da det nu kun omhandlede “en” type hund og ikke samtlige hunderacer, var det også mere realistisk at nå i mål med finkæmningen af dataet. Det fungerer sådan at man henter en fil med google images url’er, og derefter uploader man denne til Colab, hvor man så med lidt kode kan downloade billederne fra disse url’er og derefter placerede vi så disse billeder i en crossbreeds mappe på linje med de andre hunderacer. . folder = &#39;crossbreed&#39; file = &#39;urls_crossbreed.csv&#39; . dest = train_path/folder dest.mkdir(parents=True, exist_ok=True) . download_images(dest, path/file, max_pics=120) . Herfra lavede vi en zip fil, der indeholder alle billeder med crossbreeds, som vi unzipper samme sted som vi unzippede hunde datasettet før . !unzip &#39;/content/gdrive/MyDrive/crossbreeds-20210521T102410Z-001.zip&#39; -d &#39;/content/dogs&#39; . Størstedelen af finkæmningen har bestået af at fjerne duplikater, samt billeder der, fordi det er google, slet ikke består af hunde. . fns = get_image_files(path) failed = verify_images(fns) failed.map(Path.unlink) . def get_y(r): return L(parent_label(r)) . def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True): &quot;Compute accuracy when `inp` and `targ` are the same size.&quot; if sigmoid: inp = inp.sigmoid() return ((inp&gt;thresh)==targ.bool()).float().mean() . Step 2 - Data Preparation . def get_dls(bs, size): dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), splitter=RandomSplitter(valid_pct=0.2, seed=42), get_items=get_image_files, get_y=get_y, item_tfms=RandomResizedCrop(128, min_scale=0.3), batch_tfms=aug_transforms(size=size) ) return dblock.dataloaders(train_path, bs=bs) . Den første data preparation teknik er en splitter. Dermed splitter vi 20% af vores dataset ud i et valideringssæt, som bliver brugt under træningsprocessen. . RandomresizedCrop brugte vi til at tage snippet med en specifikt størrelse ud af et billedé og ændrer dens aspect ratio. Det gør dataen mere generaliseret. . Batch transformation bruges til at croppe billederne til samme størrelse for at gøre det muligt at smide en batch af billeder til GPU´en. Aug_transform roterer, flipper, warper, zoomer og ændrer kontrasten samt lysstyrken på billederne. . dls = get_dls(128, 128) dls.valid.show_batch(max_n=5, nrows=2) . Step 3 - Choose model . Formålet med at benytte denne model var at se hvad forskellen på VGG og resnet er. Hvilke resultater de kommer med, samt at prøve at lave vores egen implementering af et netværk. Her tænkte vi, at vi ville bruge et VGG-16 netværk som vores træningsmodel, da den er lavet til large-scale images. Det krævede dog at vi selv skulle træne modellen, men formålet med at opsætte modellen selv var at få en større forståelse for hvad der sker inde i boksen. Ideen er som sagt at implementere VGG16 selv og måden VGG16 fungerer er at den først tager et input af størrelse 224x224 pixels med 3 channels, altså et RGB billede. Derefter går det igennem nogle convolution lag, hvor vi har et stride på 2 og padder billedet 1 pixel af gangen. Hvert lag bruger også en ReLu funktion. Til sidst i modellen er der et softmax lag. . def get_model(): return nn.Sequential( #first to layer ConvLayer(3,64, stride=1), ConvLayer(64,64, stride=1), #second layer nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ConvLayer(64,128, stride=1), ConvLayer(128,128, stride=1), #third layer nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ConvLayer(128,256, stride=1), ConvLayer(256,256, stride=1), ConvLayer(256,256, stride=1), #fourth layer nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ConvLayer(256, 512, stride=1), ConvLayer(512,512, stride=1), ConvLayer(512,512, stride=1), #Fifth layer nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ConvLayer(512,512, stride=1), ConvLayer(512,512, stride=1), ConvLayer(512,512, stride=1), #End nn.MaxPool2d(kernel_size=3, stride=2, padding=1), Flatten(), nn.Linear(512, 4096), nn.Linear(4096,4096), nn.Linear(4096, 120), nn.Softmax(dim=1) ) . vgg_learner = Learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), metrics=accuracy).to_fp16() . Vi startede med at bruge accuracy_multi, fordi vi ville bruge vores model til at gætte på blandede racer og troede at for at få 2 eller flere labels på et billede, skulle vi bruge accuracy_multi. . learn = cnn_learner(dls, resnet18, metrics=partial(accuracy_multi, thresh=0.2)).to_fp16() . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth . . Vi bruger fp16 til at gøre træningen hurtigere, dog med lidt dårligere resultat . . Step 4 - Train Model . Når vi først træner vores model tager vi et lavt antal epochs først. Dette gør vi for lige at få en fornemmelse for hvordan modellen klarer sig, før vi begynder at bruge lang tid på at træne. Første gang vi træner vælger vi en tilfældig learning rate, da vi ikke ved hvordan det vil fungerer endnu og vi gerne vil have et udgangspunkt før vi begynder at pille for meget med de forskellige parametre. . Når vi sætter modellen til at træne går den igennem 7 steps: Initialize the parameters: Først sætter vi vores weights tilfældigt . Calculate the predictions: Udregner . Calculate the loss . Calculate the gradients . Step the weights . Repeat the process . Stop . learn.fit_one_cycle(5) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.892570 | 0.572330 | 0.072458 | 01:28 | . 1 | 0.191248 | 0.052329 | 0.991739 | 01:28 | . 2 | 0.063645 | 0.043283 | 0.991820 | 01:28 | . 3 | 0.049344 | 0.041396 | 0.991913 | 01:28 | . 4 | 0.046851 | 0.040727 | 0.991937 | 01:28 | . Efter træningen er færdig giver modellen os nogle tal, der fortæller os hvordan modellen har klaret sig. . Progressive resizing . learn.dls = get_dls(64, 224) . learn.fine_tune(5, base_lr=1e-6) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.045587 | 0.036385 | 0.992033 | 01:34 | . epoch train_loss valid_loss accuracy_multi time . 0 | 0.045448 | 0.036473 | 0.992063 | 01:38 | . 1 | 0.044707 | 0.036427 | 0.992077 | 01:38 | . 2 | 0.044614 | 0.036342 | 0.992057 | 01:38 | . 3 | 0.044757 | 0.036230 | 0.992077 | 01:41 | . 4 | 0.045245 | 0.036088 | 0.992087 | 01:38 | . Step 5 - Evaluation . learn.recorder.plot_loss() . learn.lr_find() . SuggestedLRs(lr_min=5.754399462603033e-05, lr_steep=3.981071586167673e-06) . Vi startede ud med at bruge MultiCategoryBlock classification, hvor resultater af vores model var meget unøjagtige. Vores model var alt for selvsikker. Dens accuracy gik over 99% meget hurtigt. . I starten vidste vi ikke hvorfor denne model var så præcis, derfor forsøgte vi at justere modellens threshold for at undersøge om den forholder sig til vores definerede threshold, som vi kunne konkludere at den ikke gjorde. Her forblev forudsigelserne stadigvæk alt for præcise. . preds, targs = learn.get_preds() xs = torch.linspace(0.05,1,40) accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs] plt.plot(xs,accs); . Som tidligere nævnt brugte vi MultiCategoryBlock som vi fandt ud af var en forkert classification i vores tilfælde. Vi kom frem til at vores model, ikke var i stand til at lave acceptable forudsigelser på vores datasæt, hvor den tilsyneladende ignorerer vores threshold parameters og dermed lavede forudsigelser, som i vores øjne virkede urealistiske. Dette skyldes at vi var kommet til at benytte os af multilabel classification frem for den ønskede multi category. Ved ændring af dette kom vi frem til resultater som var mere åbenlyse. . Det gjorde vi ved at ændre MultiCategoryBlock til CategoryBlock og bruge nn.CrossEntropyLoss som optimizer. . def get_dls(bs, size): dblock = DataBlock(blocks=(ImageBlock, CategoryBlock), splitter=RandomSplitter(valid_pct=0.2, seed=42), get_items=get_image_files, get_y=parent_label, item_tfms=RandomResizedCrop(128, min_scale=0.3), batch_tfms=aug_transforms(size=size) ) return dblock.dataloaders(train_path, bs=bs) . dls = get_dls(128,128) . loss = nn.CrossEntropyLoss() learn = cnn_learner(dls, resnet18, metrics=accuracy, loss_func=loss).to_fp16() . For at have lidt mere indblik i hvad modellen predictede gør vi brug af Confusion matrix . learn.fit_one_cycle(2) . epoch train_loss valid_loss accuracy time . 0 | 3.510610 | 1.776576 | 0.513540 | 01:26 | . 1 | 2.375955 | 1.545592 | 0.572534 | 01:25 | . learn.dls = get_dls(64,256) . learn.fine_tune(2) . epoch train_loss valid_loss accuracy time . 0 | 1.730646 | 0.972300 | 0.698017 | 01:33 | . epoch train_loss valid_loss accuracy time . 0 | 1.422808 | 0.841520 | 0.752176 | 01:37 | . 1 | 1.133231 | 0.739572 | 0.779014 | 01:37 | . interp = ClassificationInterpretation.from_learner(learn) . interp.most_confused(min_val=5) . interp.plot_confusion_matrix(figsize=(48,48)) . Tidligere har vi brugt confusion matrix, hvor det viste sig at modellen havde svært ved særligt 4 hunderacer. Hvis vi kigger på vores data kan vi se at disse racer meget ligner hinanden og dermed bedre forstå hvorfor vores model kan forveksle dem med hinanden. Vi kan også rette vores data til efter, eller forsøge at forstå hvilke billeder den gætter forkert på og hvorfor. . Step 6 - Tuning . For at øge accuracy af modellen implementerer vi yderligere teknikker. Vi begynder ved DataBlock´en, hvor vi tilføjer Normalization i batch transformation. Vi vil også bruge progressive resizing når vi skal træne vores model. . def get_dls(bs, size): dblock = DataBlock(blocks=(ImageBlock, CategoryBlock), splitter=RandomSplitter(valid_pct=0.2, seed=42), get_items=get_image_files, get_y=parent_label, item_tfms=RandomResizedCrop(128, min_scale=0.3), batch_tfms=[*aug_transforms(size=size), Normalize()] ) return dblock.dataloaders(train_path, bs=bs) . dls = get_dls(128, 128) . Så tilføjer vi MixUp til vores cnn_learner. Derudover tilføjer vi også Label Smoothing til vores træning. . learn = cnn_learner(dls, resnet18, metrics=accuracy, loss_func=LabelSmoothingCrossEntropy(), cbs=MixUp).to_fp16() . Som vi har observeret i vores evaluering er der plads til flere epochs i vores træning. . learn.fit_one_cycle(10) . epoch train_loss valid_loss accuracy time . 0 | 5.892113 | 3.796050 | 0.194633 | 01:30 | . 1 | 4.361841 | 2.472106 | 0.506770 | 01:26 | . 2 | 3.707605 | 2.202650 | 0.570841 | 01:26 | . 3 | 3.413938 | 2.136667 | 0.589700 | 01:29 | . 4 | 3.254255 | 2.074065 | 0.604691 | 01:28 | . 5 | 3.160493 | 2.041378 | 0.616296 | 01:26 | . 6 | 3.079693 | 2.010094 | 0.623308 | 01:27 | . 7 | 3.026370 | 1.985075 | 0.639507 | 01:27 | . 8 | 3.002722 | 1.979679 | 0.639749 | 01:27 | . 9 | 2.997378 | 1.977029 | 0.641683 | 01:28 | . learn.dls = get_dls(64, 256) . learn.fine_tune(7) . epoch train_loss valid_loss accuracy time . 0 | 3.016368 | 1.800929 | 0.698743 | 01:37 | . epoch train_loss valid_loss accuracy time . 0 | 2.833165 | 1.632907 | 0.759188 | 01:40 | . 1 | 2.793709 | 1.669587 | 0.738395 | 01:39 | . 2 | 2.759622 | 1.652440 | 0.744681 | 01:39 | . 3 | 2.643527 | 1.577401 | 0.769342 | 01:39 | . 4 | 2.578503 | 1.534416 | 0.780948 | 01:39 | . 5 | 2.530799 | 1.512727 | 0.789410 | 01:39 | . 6 | 2.489577 | 1.508128 | 0.789410 | 01:40 | . Step 7 - Prediction . Her finder vi et tilfældigt hunde-billede og uploader det til Jupyter Notebook . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) img.show() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc497321390&gt; . Vi predicter på vores billede . pred,pred_idx,probs = learn.predict(img) . pred_value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; pred_value . &#39;Prediction: n02089867-Walker_hound; Probability: 0.4911&#39; . Vi kan se hvad modellen predicter på vores billede . Hvis vi havde et test sæt ville vi kunne predicte over det i stedet for at tage et tilfældigt billede fra Google . learn.save(&quot;dog_classifier&quot;) . Path(&#39;models/dog_classifier.pth&#39;) . Når/hvis vi er tilfreds med vores model, kan vi gemme den . learn.load(&quot;dog_classifier&quot;) . Vi kan hente vores model ind i vores projekt, hvis vi vil bruge den senere eller til fremtidige projekter .",
            "url": "https://ande6059.github.io/AndersBlog/2021/05/23/_05_25_ai_eksamen_projekt.html",
            "relUrl": "/2021/05/23/_05_25_ai_eksamen_projekt.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ande6059.github.io/AndersBlog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ande6059.github.io/AndersBlog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ande6059.github.io/AndersBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ande6059.github.io/AndersBlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}